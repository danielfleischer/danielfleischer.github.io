<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>          Agree &amp; Join LinkedIn
        
  By clicking Continue to join or sign in, you agree to LinkedInâ€™s User Agreement, Privacy Policy, and Cookie Policy.
ğŸ“¬ I built an MCP server that lets LLMs search my email from the terminal
</code></pre></div></div> <p>The server connects Claude to email search via the mu CLI tool. Now I just ask it things like: â€œFind emails with PDF attachments from last Aprilâ€ âš¡</p> <p>ğŸ›  No custom frontend. No heavy framework. Just a CLI tool made smarter.</p> <p>ğŸ’¡ I learned that MCP servers are basically API translators â€” they take complex developer SDKs and flatten them into simple function calls that LLMs can actually use.</p> <p>ğŸ¯ The bigger picture: This pattern can breathe new life into existing CLI tools and services. Complex APIs â†’ Simple, declarative functions â†’ Natural language queries.</p> <p>This isnâ€™t a product â€” just an experiment in stitching new capabilities into existing workflows. Code here: https://lnkd.in/eT2fJBSv</p> <p>mu email indexer and searcher: https://github.com/djcb/mu</p> <p>#MCP #LLM #EmailSearch #OpenSource #AI</p> <p>What existing tools would you want to make LLM-friendly? ğŸ¤” To view or add a comment, sign in Whenever I am building complex ğ€ğ ğğ§ğ­ğ¢ğœ ğ’ğ²ğ¬ğ­ğğ¦ğ¬, I mostly end up adding a lot of ğ¥ğšğ­ğğ§ğœğ²Â to the system. And personally, these two techniques have always helped me a lot with reducing latency:</p> <ul> <li>ğğšğ«ğšğ¥ğ¥ğğ¥ğ¢ğ³ğšğ­ğ¢ğ¨ğ§: If your agent has several steps that donâ€™t depend on each other, you can run them at the same time instead of one after another â€” this makes things much faster. But in a real production system, you have to be careful to avoid data conflicts (known as data races) when those parallel steps access shared information.</li> </ul> <p>In that case, if you are running five processes inside the logic of your agent, and all of them are taking 3 seconds: Without parallelization: 3x5 = ğŸğŸ“ğ¬ (ğğšğ ğ”ğ—) With Parallelization: 3x1 = ğŸ‘ğ¬Â (ğ†ğ¨ğ¨ğ ğ”ğ—)</p> <ul> <li>ğ’ğ­ğ«ğğšğ¦ğ¢ğ§ğ : Sometimes, you canâ€™t make your agent actually faster without sacrificing quality. In that case, focus on improving how fast it feels to the user â€” whatâ€™s called perceived latency. You can do this by showing helpful updates while the agent works â€” like a progress bar, a list of key actions itâ€™s taking, or even streaming the AIâ€™s response live, word by word, as itâ€™s being generated.</li> </ul> <p>Because streaming keeps the user engaged. If you are a web developer, you know the importance of a loader when a process is happening or waiting for an API response. If you have used Cursor or some coding agent, you would have experienced that it shows you:</p> <ul> <li>The todos it is organizing</li> <li>The code it is reading</li> <li>The Edits it is making</li> <li>Different files it is working on</li> <li>Different commands it is executing Guess what if it doesnâ€™t show us anything and only comes after 5 minutes. I may end up closing it mid-way for sure ğŸ˜… Thatâ€™s the importance of Streaming</li> </ul> <p>ğ‘Šâ„ğ‘ğ‘¡ ğ‘‘ğ‘–ğ‘“ğ‘“ğ‘’ğ‘Ÿğ‘’ğ‘›ğ‘¡ ğ‘¡ğ‘’ğ‘â„ğ‘›ğ‘–ğ‘ğ‘¢ğ‘’ğ‘  ğ‘‘ğ‘œ ğ‘¦ğ‘œğ‘¢ ğ‘ğ‘’ğ‘Ÿğ‘ ğ‘œğ‘›ğ‘ğ‘™ğ‘™ğ‘¦ ğ‘¢ğ‘ ğ‘’ ğ‘¡ğ‘œ â„ğ‘’ğ‘™ğ‘ ğ‘¤ğ‘–ğ‘¡â„ ğ‘¡â„ğ‘’ ğ‘™ğ‘ğ‘¡ğ‘’ğ‘›ğ‘ğ‘¦ ğ‘–ğ‘› ğ‘ğ‘œğ‘šğ‘ğ‘™ğ‘’ğ‘¥ ğ´ğ‘”ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘ ğ‘ ğ‘¦ğ‘ ğ‘¡ğ‘’ğ‘šğ‘ ?</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    To view or add a comment, sign in
You've built your FastAPI application. Tests pass. It works locally. Now you're reading deployment guides and drowning in advice about connection pool tuning, PostgreSQL JIT compilation, and async event loop optimization.
</code></pre></div></div> <p>Hereâ€™s the problem: youâ€™re optimizing blind. You donâ€™t have production traffic to measure. You donâ€™t know where your bottlenecks are.</p> <p>Meanwhile, the stuff that will actually break on day one gets buried in the noise. Iâ€™ve seen developers spend days tuning connection pools for traffic they donâ€™t have yet, while missing the fact that their authentication breaks in production or their database credentials arenâ€™t set correctly.</p> <p>The truth is, before your first deployment, only three things actually matter:</p> <ul> <li>Donâ€™t get hacked (security configurations that prevent immediate exploitation)</li> <li>Donâ€™t break immediately (configuration that prevents instant failures)</li> <li>Know whatâ€™s happening (minimal observability so you can actually debug issues)</li> </ul> <p>Everything else - performance tuning, advanced monitoring, sophisticated caching - can wait until you have real data.</p> <p>I just published a practical checklist covering exactly what matters in the hour before you go live. No overwhelming theory. Just the non-negotiables explained with real examples of what happens when you skip them.</p> <p>Link in the comments!</p> <p>#python #fastapi #webdev #deployment</p> <hr> <p>Want to skip deployment configuration entirely? Check out FastroAI at https://fastro.ai - a production-ready FastAPI template with security, monitoring, and deployment already configured correctly. To view or add a comment, sign in Tried my hands on web scraping and AI-powered document processing recently.</p> <p>I built a pipeline that crawls configured websites, filters PDFs by exam type and year, and downloads them in a structured way. Both the exam name and years are configurable through the config file.</p> <p>Instead of using traditional parsing methods, I integrated Claude (Sonnet 4) to directly read PDFs, extract questions and options, and tag them with subject, topic, difficulty level, and many more attributes â€” all in one step. The processed data exports to Google Sheets for easy analysis and organization.</p> <p>The project includes three CLI commands for crawling, tagging with Claude, and exporting to Sheets, keeping the workflow modular and composable.</p> <p>Hereâ€™s a demo dataset from one of the runs showcasing the structured output. This setup uses exam papers from two years: https://surl.li/rhsnmg</p> <p>Tech stack: Node.js, TypeScript, Claude API, Google Sheets API</p> <p>GitHub Repo: https://lnkd.in/g4kdAvFE</p> <p>#AI #WebScraping #Automation To view or add a comment, sign in</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              446 followers
          Actions, Not Just Chat   React Component GPT:
</code></pre></div></div> <p>We need a GPT that understands our React components, knows our CSS variables, and can spit out code thatâ€™s ready to use. This isnâ€™t about general knowledge; itâ€™s about our knowledge. The standard GPT knowledge upload is fine for broad docs, but for precise component generation, we need control. Thatâ€™s where Actions come in. Our design system lives in zeroheight. Our CSS variables are in a .css file. Our React components are in .jsx files. These are all discrete sources of truth. A generic LLM has no idea how they connect. If someone asks for a â€œprimary button,â€ it might give generic HTML, not our Button component with â€“color-brand-primary. Unacceptable. We build an API. This API becomes our â€œknowledge retrieval service.â€ The GPT uses Actions to call this API when it needs specific, localized data. Extract Data (The ETL of our Design System): zeroheight Content: Use the zeroheight API to pull down all component documentation. Store it, parse it, clean it. Weâ€™re i https://lnkd.in/gufWti_X To view or add a comment, sign in</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              299 followers
          Actions, Not Just Chat 
</code></pre></div></div> <p>React Component GPT:</p> <p>We need a GPT that understands our React components, knows our CSS variables, and can spit out code thatâ€™s ready to use. This isnâ€™t about general knowledge; itâ€™s about our knowledge. The standard GPT knowledge upload is fine for broad docs, but for precise component generation, we need control. Thatâ€™s where Actions come in. Our design system lives in zeroheight. Our CSS variables are in a .css file. Our React components are in .jsx files. These are all discrete sources of truth. A generic LLM has no idea how they connect. If someone asks for a â€œprimary button,â€ it might give generic HTML, not our Button component with â€“color-brand-primary. Unacceptable. We build an API. This API becomes our â€œknowledge retrieval service.â€ The GPT uses Actions to call this API when it needs specific, localized data. Extract Data (The ETL of our Design System): zeroheight Content: Use the zeroheight API to pull down all component documentation. Store it, parse it, clean it. Weâ€™re i</p> <p>https://lnkd.in/gufWti_X To view or add a comment, sign in</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              446 followers
          API-Mocker Hits 5.38K Downloads: The Open Source API Development Platform That's Changing How Developers Mock APIs   The Problem Every Developer Faces
</code></pre></div></div> <p>Building modern applications means integrating with countless APIs. But what happens when those APIs are down, rate-limited, or simply donâ€™t exist yet? Most developers resort to basic mocking tools that barely scratch the surface of real-world API complexity. API-Mocker isnâ€™t just another mocking tool. Itâ€™s a comprehensive API development platform that has already been downloaded over 5,380 times by developers worldwide. Hereâ€™s what makes it different: FastAPI-based server with advanced routing and regex pattern matching AI-powered mock generation using OpenAI GPT models with intelligent fallback Scenario-based mocking for testing different API states and edge cases Smart response matching that analyzes request data for intelligent response selection GraphQL support with schema introspection and subscription handling WebSocket mocking for real-time communication testing Advanced authentication with OAuth2, JWT, API keys, and MFA support Database inte https://lnkd.in/gYKbM7Ku To view or add a comment, sign in API-Mocker Hits 5.38K Downloads: The Open Source API Development Platform Thatâ€™s Changing How Developers Mock APIs The Problem Every Developer Faces</p> <p>Building modern applications means integrating with countless APIs. But what happens when those APIs are down, rate-limited, or simply donâ€™t exist yet? Most developers resort to basic mocking tools that barely scratch the surface of real-world API complexity. API-Mocker isnâ€™t just another mocking tool. Itâ€™s a comprehensive API development platform that has already been downloaded over 5,380 times by developers worldwide. Hereâ€™s what makes it different: FastAPI-based server with advanced routing and regex pattern matching AI-powered mock generation using OpenAI GPT models with intelligent fallback Scenario-based mocking for testing different API states and edge cases Smart response matching that analyzes request data for intelligent response selection GraphQL support with schema introspection and subscription handling WebSocket mocking for real-time communication testing Advanced authentication with OAuth2, JWT, API keys, and MFA support Database inte https://lnkd.in/gYKbM7Ku To view or add a comment, sign in WKassebaumâ€™s fork of zen-mcp-server seems to be better maintained than the official version, with support for more LLMs from different providers. For those unfamiliar:</p> <p>zen-mcp-server is a â€œModel Context Protocol server that supercharges tools likeÂ Claude Code,Â Codex CLI, and IDE clients such asÂ CursorÂ or theÂ Claude Dev VS Code extension.Â Zen MCP connects your favorite AI tool to multiple AI modelsÂ for enhanced code analysis, problem-solving, and collaborative developmentâ€.</p> <p>https://lnkd.in/efRqQ7PH To view or add a comment, sign in The Cloudflare Code Mode approach to MCP tool calls (https://lnkd.in/erdnK7EH) sounds like a really significant improvement on the MCP experience. Itâ€™s one of those rare breakthroughs that is both elegant and obvious in hindsight.</p> <p>At a high level, the idea is to translate â€œraw MCPâ€ into TypeScript interfaces, and ask the LLM to code against the TypeScript interface. Itâ€™s a form of language arbitrage you might say: the agent exchanges a low-resource language (raw MCP) for a high-resource language (TypeScript), so the LLM performs much better. Then something cool happens - the LLM can also write code to chain tool calls together, or otherwise process the tool call responses in interesting ways. The agent is left holding a bunch of LLM-generated code, so it needs a sandbox to go run that code, and of course Cloudflare offers a solution for that.</p> <p>Weâ€™ll see if this approach takes hold; it seems to have a lot of traction already. If it does, then itâ€™s worth asking whether the MCP protocol itself needs a revision - for example, by making the MCP server provide the TypeScript interface natively. That then raises another round of questions, around what is the best way for MCP servers to â€œspeakâ€ to LLMs - can we do better than Typeface?</p> <p>Certainly itâ€™s a cool idea, and I think itâ€™s a great step forward for MCP usage.</p> <p>h/t to Kushagra Kumar for sending this post my way! To view or add a comment, sign in ğŸ’¡ ğ—¡ğ—²ğ˜ƒğ—²ğ—¿ ğ—¹ğ—¼ğ˜€ğ—² ğ˜ğ—¿ğ—®ğ—°ğ—¸ ğ—¼ğ—³ ğ—¶ğ—ºğ—½ğ—¼ğ—¿ğ˜ğ—®ğ—»ğ˜ ğ—¶ğ—»ğ—³ğ—¼ğ—¿ğ—ºğ—®ğ˜ğ—¶ğ—¼ğ—» ğ—®ğ—´ğ—®ğ—¶ğ—».</p> <p>Just released MCP Memory Service v8.6.0 with ğ——ğ—¼ğ—°ğ˜‚ğ—ºğ—²ğ—»ğ˜ ğ—œğ—»ğ—´ğ—²ğ˜€ğ˜ğ—¶ğ—¼ğ—» - your personal AI-powered knowledge base.</p> <p>ğ—§ğ—µğ—² ğ—£ğ—¿ğ—¼ğ—¯ğ—¹ğ—²ğ—º: You have PDFs, documentation, notes scattered everywhere. Finding the right information takes forever. Context is lost between AI conversations.</p> <p>ğ—§ğ—µğ—² ğ—¦ğ—¼ğ—¹ğ˜‚ğ˜ğ—¶ğ—¼ğ—»: Upload your documents once. Search them semantically. Let AI remember everything for you.</p> <p>ğ—›ğ—¼ğ˜„ ğ—¶ğ˜ ğ—ªğ—¼ğ—¿ğ—¸ğ˜€:</p> <p>1ï¸âƒ£ ğ—¨ğ—½ğ—¹ğ—¼ğ—®ğ—± - Drag PDFs, docs, or notes to the web interface 2ï¸âƒ£ ğ—£ğ—¿ğ—¼ğ—°ğ—²ğ˜€ğ˜€ - Intelligent chunking preserves context 3ï¸âƒ£ ğ—¦ğ—²ğ—®ğ—¿ğ—°ğ—µ - Ask in natural language: â€œauthentication flow from the security docsâ€ 4ï¸âƒ£ ğ—¥ğ—²ğ—ºğ—²ğ—ºğ—¯ğ—²ğ—¿ - AI assistants access this knowledge automatically</p> <p>ğ—ªğ—µğ—®ğ˜ ğ— ğ—®ğ—¸ğ—²ğ˜€ ğ—§ğ—µğ—¶ğ˜€ ğ—¦ğ—½ğ—²ğ—°ğ—¶ğ—®ğ—¹:</p> <p>ğŸŒŸ ğ—¦ğ—²ğ—ºğ—®ğ—»ğ˜ğ—¶ğ—° ğ—¦ğ—²ğ—®ğ—¿ğ—°ğ—µ - Finds relevant content, not just keywords ğŸŒŸ ğ—£ğ—¿ğ—¶ğ˜ƒğ—®ğ—°ğ˜†-ğ—™ğ—¶ğ—¿ğ˜€ğ˜ - Runs locally on your machine (or your teamâ€™s server) ğŸŒŸ ğ—¨ğ—»ğ—¶ğ˜ƒğ—²ğ—¿ğ˜€ğ—®ğ—¹ - Works with Claude, VS Code, Cursor, and 13+ AI applications ğŸŒŸ ğ—£ğ—¿ğ—¼ğ—±ğ˜‚ğ—°ğ˜ğ—¶ğ—¼ğ—» ğ—¥ğ—²ğ—®ğ—±ğ˜† - 2000+ memories in active deployments, &lt;500ms search times</p> <p>ğ—•ğ˜‚ğ—¶ğ—¹ğ˜ ğ—³ğ—¼ğ—¿ ğ—§ğ—²ğ—®ğ—ºğ˜€: â€¢ OAuth 2.1 collaboration â€¢ Hybrid sync (local + cloud) â€¢ Zero-configuration setup â€¢ Enterprise security</p> <p>From solo developers to entire teams - one source of truth for AI-powered work.</p> <p>ğ—¢ğ—½ğ—²ğ—» ğ—¦ğ—¼ğ˜‚ğ—¿ğ—°ğ—² &amp; ğ—™ğ—¿ğ—²ğ—²: ğŸ‘‰ https://lnkd.in/ePYekaAF</p> <p>#ArtificialIntelligence #Productivity #KnowledgeManagement #DeveloperTools #OpenSource #Claude #AI To view or add a comment, sign in</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        1,444 followers
      
                Create your free account or sign in to continue your search
              
          or
        
  By clicking Continue to join or sign in, you agree to LinkedInâ€™s User Agreement, Privacy Policy, and Cookie Policy.

            New to LinkedIn? Join now
          
                      or
                    
                New to LinkedIn? Join now
              
  By clicking Continue to join or sign in, you agree to LinkedInâ€™s User Agreement, Privacy Policy, and Cookie Policy.
</code></pre></div></div> </body></html>